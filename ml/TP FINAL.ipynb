{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3810300591          0        100 ...         21        101         30]\n",
      " [3810300590          0         69 ...         14          7         95]\n",
      " [3810300589          1         41 ...         16         12         87]\n",
      " ...\n",
      " [3809780562          0         86 ...         51          1         12]\n",
      " [3809780560          0         10 ...          5         98         67]\n",
      " [3809780558          0         86 ...         18         16         99]]\n"
     ]
    }
   ],
   "source": [
    "m = np.loadtxt('dota_data.txt', dtype=int)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_synnergy(lines):\n",
    "    matches_pairs = np.zeros((121, 121))\n",
    "    wins_pairs = np.zeros((121, 121)) \n",
    "    wr_pairs = np.zeros((121, 121))\n",
    "\n",
    "    for line in lines:\n",
    "        rad_wins = line[1] == 1\n",
    "        dire_wins = not rad_wins\n",
    "        heroes = line[2:]\n",
    "        rad = heroes[:5]\n",
    "        dire = heroes[5:]\n",
    "\n",
    "        for team in [rad, dire]:\n",
    "            for i in range(5):\n",
    "                hero1 = team[i]\n",
    "                for j in range(i, 5):\n",
    "                    hero2 = team[j]\n",
    "                    matches_pairs[hero1, hero2] += 1\n",
    "                    matches_pairs[hero2, hero1] += 1\n",
    "                    if rad_wins and hero1 in rad:\n",
    "                        wins_pairs[hero1, hero2] += 1 \n",
    "                        wins_pairs[hero2, hero1] += 1 \n",
    "                    elif dire_wins and hero1 in dire:\n",
    "                        wins_pairs[hero1, hero2] += 1\n",
    "                        wins_pairs[hero2, hero1] += 1\n",
    "\n",
    "    matches_pairs[matches_pairs == 0] = 1\n",
    "    wr_pairs = wins_pairs / matches_pairs\n",
    "    return wr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_counters(lines):\n",
    "    matches_counter = np.zeros((121, 121))\n",
    "    wins_counter = np.zeros((121, 121)) \n",
    "    wr_counter = np.zeros((121, 121))\n",
    "\n",
    "    for line in m:\n",
    "        rad_wins = line[1] == 1\n",
    "        dire_wins = not rad_wins\n",
    "        heroes = line[2:]\n",
    "        rad = heroes[:5]\n",
    "        dire = heroes[5:]\n",
    "\n",
    "        #rad first\n",
    "        for hero1 in rad:\n",
    "            for hero2 in dire:\n",
    "                matches_counter[hero1, hero2] += 1\n",
    "                if rad_wins: wins_counter[hero1, hero2] += 1\n",
    "\n",
    "        #dire first\n",
    "        for hero1 in dire:\n",
    "            for hero2 in rad:\n",
    "                matches_counter[hero1, hero2] += 1\n",
    "                if dire_wins: wins_counter[hero1, hero2] += 1\n",
    "\n",
    "\n",
    "    matches_counter[matches_counter == 0] = 1\n",
    "    wr_counter = wins_counter / matches_counter\n",
    "    return wr_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 0.9\n",
    "train_size = int(len(m) * factor)\n",
    "wr_pairs = compute_synnergy(m[: train_size])\n",
    "wr_counters = compute_counters(m[ : train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wr_counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_test(lines, valp):\n",
    "    feats = 121 + 55\n",
    "    #feats = 10 + 20 + 25\n",
    "    train_size = int(len(lines) * (1 - valp))\n",
    "    test_size = len(lines) - train_size\n",
    "    data = {'train': {}, 'test': {}}\n",
    "    data['train']['in'] = np.zeros((train_size, feats))\n",
    "    data['train']['out'] = np.zeros((train_size), dtype=int)\n",
    "    data['test']['in'] = np.zeros((test_size, feats))\n",
    "    data['test']['out'] = np.zeros((test_size), dtype=int)\n",
    "    data['test']['lines'] = lines[train_size : ]\n",
    "    data['train']['lines'] = lines[ : train_size]\n",
    "    \n",
    "    #wr_pairs = compute_synnergy(data['train']['lines'])\n",
    "    #wr_counters = compute_counters(data['train']['lines'])\n",
    "\n",
    "    for kind in ['train', 'test']:\n",
    "        for i in range(len(data[kind]['lines'])):\n",
    "            line = data[kind]['lines'][i]\n",
    "            \n",
    "            #print(line)\n",
    "            \n",
    "            inputs = data[kind]['in'][i]\n",
    "        \n",
    "            data[kind]['out'][i] = line[1]\n",
    "\n",
    "            heroes = line[2:]\n",
    "            rad = heroes[:5]\n",
    "            dire = heroes[5:]\n",
    "            \n",
    "            for hero in rad:\n",
    "                inputs[hero] = 1\n",
    "\n",
    "            for hero in dire:\n",
    "                inputs[hero] = -1\n",
    "            \n",
    "            counter = 121\n",
    "\n",
    "            for hero_i in range(5):\n",
    "                for hero_j in range(hero_i, 5):\n",
    "                    inputs[counter] = wr_pairs[rad[hero_i], rad[hero_j]]\n",
    "                    counter += 1\n",
    "\n",
    "            for hero_i in range(5):\n",
    "                for hero_j in range(hero_i, 5):\n",
    "                    inputs[counter] = - wr_pairs[dire[hero_i], dire[hero_j]]\n",
    "                    counter += 1\n",
    "\n",
    "            for hero_i in range(5):\n",
    "                for hero_j in range(5):\n",
    "                    inputs[counter] = wr_counters[rad[hero_i], dire[hero_j]]\n",
    "                    counter += 1\n",
    "                    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -1.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -1.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -1.          0.          0.          1.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -1.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  1.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          1.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -1.          1.          0.          0.\n",
      "  0.          0.          1.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.53547247  0.50232952  0.53089598  0.47162162  0.52094496\n",
      "  0.46701604  0.44598099  0.40960285  0.4578702   0.47620397  0.4454004\n",
      "  0.45546397  0.46482308  0.43367043  0.48402901 -0.57475676 -0.58417936\n",
      " -0.60612245 -0.47889908 -0.6785553  -0.51059751 -0.53163136 -0.45436508\n",
      " -0.59675481 -0.52056645 -0.47715736 -0.60650819 -0.44676474 -0.52031455\n",
      " -0.58375619  0.47058824  0.52775142  0.52287195  0.54857143  0.48348706\n",
      "  0.39231457  0.44675325  0.44361483  0.49836423  0.39333575  0.39726595\n",
      "  0.46065101  0.45636605  0.53234266  0.38967136  0.37676056  0.4654816\n",
      "  0.43744334  0.54141104  0.3888131   0.40078475  0.45467544  0.45620476\n",
      "  0.55631659  0.39141521]\n"
     ]
    }
   ],
   "source": [
    "data = gen_train_test(m, 0.1)\n",
    "print(data['train']['in'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 161442 samples, validate on 17938 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/SGD/Variable_3/Assign = Assign[T=DT_FLOAT, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_1/SGD/Variable_3, dense_5/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training_1/SGD/Variable_3/Assign', defined at:\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-95b358db7743>\", line 22, in <module>\n    batch_size=512, validation_data=(data['test']['in'], data['test']['out']))\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/models.py\", line 963, in fit\n    validation_steps=validation_steps)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1682, in fit\n    self._make_train_function()\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 182, in get_updates\n    moments = [K.zeros(shape) for shape in shapes]\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 182, in <listcomp>\n    moments = [K.zeros(shape) for shape in shapes]\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 694, in zeros\n    return variable(v, dtype=dtype, name=name)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 395, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 387, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 283, in assign\n    validate_shape=validate_shape)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 60, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/SGD/Variable_3/Assign = Assign[T=DT_FLOAT, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_1/SGD/Variable_3, dense_5/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/SGD/Variable_3/Assign = Assign[T=DT_FLOAT, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_1/SGD/Variable_3, dense_5/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-95b358db7743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m model.fit(data['train']['in'], data['train']['out'],\n\u001b[1;32m     21\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m           batch_size=512, validation_data=(data['test']['in'], data['test']['out']))\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'in'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mestrado/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/mestrado/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/mestrado/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mestrado/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2474\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2476\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2478\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[0;32m~/mestrado/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/SGD/Variable_3/Assign = Assign[T=DT_FLOAT, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_1/SGD/Variable_3, dense_5/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training_1/SGD/Variable_3/Assign', defined at:\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-95b358db7743>\", line 22, in <module>\n    batch_size=512, validation_data=(data['test']['in'], data['test']['out']))\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/models.py\", line 963, in fit\n    validation_steps=validation_steps)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1682, in fit\n    self._make_train_function()\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 182, in get_updates\n    moments = [K.zeros(shape) for shape in shapes]\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 182, in <listcomp>\n    moments = [K.zeros(shape) for shape in shapes]\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 694, in zeros\n    return variable(v, dtype=dtype, name=name)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 395, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 387, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 283, in assign\n    validate_shape=validate_shape)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 60, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/rafael/mestrado/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/SGD/Variable_3/Assign = Assign[T=DT_FLOAT, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_1/SGD/Variable_3, dense_5/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adagrad, Adam\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, activation='relu', input_dim=len(data['train']['in'][0])))\n",
    "model.add(Dense(300, activation='relu', input_dim=len(data['train']['in'][0])))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.05)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              #optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              #optimizer='adadelta',\n",
    "              optimizer=sgd,\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(data['train']['in'], data['train']['out'],\n",
    "          epochs=1000,\n",
    "          batch_size=512, validation_data=(data['test']['in'], data['test']['out']))\n",
    "\n",
    "result = model.evaluate(data['test']['in'], data['test']['out'])\n",
    "\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_features=11, min_samples_split=2, max_depth=None, n_jobs=8)\n",
    "clf = clf.fit(data['train']['in'], data['train']['out'])\n",
    "clf_forest = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf = clf.fit(data['train']['in'], data['train']['out'])\n",
    "clf_log = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(5, weights='uniform')\n",
    "clf = clf.fit(data['train']['in'], data['train']['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "# from sklearn import svm\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(data['train']['in'], data['train']['out'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=10000)\n",
    "clf = clf.fit(data['train']['in'], data['train']['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf = clf.fit(data['train']['in'], data['train']['out'])\n",
    "clf_naive = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=2000, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "clf = clf.fit(data['train']['in'], data['train']['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = BaggingClassifier(LogisticRegression(),\n",
    "                             max_samples=0.5, max_features=0.5)\n",
    "clf = clf.fit(data['train']['in'], data['train']['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf = VotingClassifier(estimators=[('for', clf_forest), ('naive', clf_naive), ('log', clf_log)], voting='soft', weights=[1,2,2])\n",
    "clf = clf.fit(data['train']['in'], data['train']['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('oi')\n",
    "model = clf\n",
    "preds = model.predict(data['test']['in'])\n",
    "correct = data['test']['out']\n",
    "\n",
    "eq = 0\n",
    "\n",
    "wrong = []\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    if correct[i] == preds[i]:\n",
    "        eq += 1\n",
    "    else:\n",
    "        wrong.append(i)\n",
    "        \n",
    "print(eq / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_forest = wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wrong_log)\n",
    "print(wrong_naive)\n",
    "print(wrong_forest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
