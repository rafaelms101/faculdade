{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "supps = [7, 23, 57, 83, 91, 110, 9, 20, 89, 5, 21, 25, 27, 58, 64, 66, 75, 84, 86, 87, 90, 101, 111, 119, 16, 42, \n",
    "         85, 102, 108, 40, 3, 31, 26, 30, 37, 50, 52, 68, 79, 92, 112]\n",
    "\n",
    "cores = [18, 19, 23, 49, 59, 73, 78, 99, 104, 1, 6, 8, 9, 10, 12, 32, 35, 46, 48, 70, 72, 80, 89, 95, 106, 114, \n",
    "         120, 17, 21, 25, 34, 53, 75, 28, 42, 54, 60, 69, 71, 77, 81, 102, 4, 11, 15, 41, 44, 47, 56, 61, 63, 67, \n",
    "         82, 93, 94, 109, 113, 36, 39, 43, 52, 74, 76]\n",
    "\n",
    "idToHero = {1: 'antimage', 2: 'axe', 3: 'bane', 4: 'bloodseeker', 5: 'crystal_maiden', 6: 'drow_ranger', \n",
    "            7: 'earthshaker', 8: 'juggernaut', 9: 'mirana', 11: 'nevermore', 10: 'morphling', 12: 'phantom_lancer', \n",
    "            13: 'puck', 14: 'pudge', 15: 'razor', 16: 'sand_king', 17: 'storm_spirit', 18: 'sven', 19: 'tiny', \n",
    "            20: 'vengefulspirit', 21: 'windrunner', 22: 'zuus', 23: 'kunkka', 25: 'lina', 31: 'lich', 26: 'lion', \n",
    "            27: 'shadow_shaman', 28: 'slardar', 29: 'tidehunter', 30: 'witch_doctor', 32: 'riki', 33: 'enigma', \n",
    "            34: 'tinker', 35: 'sniper', 36: 'necrolyte', 37: 'warlock', 38: 'beastmaster', 39: 'queenofpain', \n",
    "            40: 'venomancer', 41: 'faceless_void', 42: 'skeleton_king', 43: 'death_prophet', 44: 'phantom_assassin',\n",
    "            45: 'pugna', 46: 'templar_assassin', 47: 'viper', 48: 'luna', 49: 'dragon_knight', 50: 'dazzle', 51: \n",
    "            'rattletrap', 52: 'leshrac', 53: 'furion', 54: 'life_stealer', 55: 'dark_seer', 56: 'clinkz', \n",
    "            57: 'omniknight', 58: 'enchantress', 59: 'huskar', 60: 'night_stalker', 61: 'broodmother', \n",
    "            62: 'bounty_hunter', 63: 'weaver', 64: 'jakiro', 65: 'batrider', 66: 'chen', 67: 'spectre', \n",
    "            69: 'doom_bringer', 68: 'ancient_apparition', 70: 'ursa', 71: 'spirit_breaker', 72: 'gyrocopter', \n",
    "            73: 'alchemist', 74: 'invoker', 75: 'silencer', 76: 'obsidian_destroyer', 77: 'lycan', \n",
    "            78: 'brewmaster', 79: 'shadow_demon', 80: 'lone_druid', 81: 'chaos_knight', 82: 'meepo', 83: 'treant', \n",
    "            84: 'ogre_magi', 85: 'undying', 86: 'rubick', 87: 'disruptor', 88: 'nyx_assassin', 89: 'naga_siren', \n",
    "            90: 'keeper_of_the_light', 91: 'wisp', 92: 'visage', 93: 'slark', 94: 'medusa', 95: 'troll_warlord', \n",
    "            96: 'centaur', 97: 'magnataur', 98: 'shredder', 99: 'bristleback', 100: 'tusk', 101: 'skywrath_mage', \n",
    "            102: 'abaddon', 103: 'elder_titan', 104: 'legion_commander', 106: 'ember_spirit', 107: 'earth_spirit', \n",
    "            109: 'terrorblade', 110: 'phoenix', 111: 'oracle', 105: 'techies', 112: 'winter_wyvern', \n",
    "            113: 'arc_warden', 108: 'abyssal_underlord', 114: 'monkey_king', 120: 'pangolier', 119: 'dark_willow'}\n",
    "\n",
    "print(len(supps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rad: ['crystal_maiden', 'vengefulspirit', 'windrunner', 'bristleback', 'monkey_king']\n",
      "Dire: ['bloodseeker', 'zuus', 'lion', 'riki']\n",
      "[ 0.  0.  0.  0. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  1. -1.  0.  0.  0. -1.  0.  0.  0.  0.  0. -1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "def print_heroes(match):\n",
    "    rad = [id for (id, team) in enumerate(match) if team == 1]\n",
    "    dire = [id for (id, team) in enumerate(match) if team == -1]\n",
    "    print('Rad:', [idToHero[id] for id in rad])\n",
    "    print('Dire:', [idToHero[id] for id in dire])\n",
    "\n",
    "match[1] = 0\n",
    "print_heroes(match)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3955048372          0         22 ...          4         22         32]\n",
      " [3955048368          1         22 ...         42         32         48]\n",
      " [3955048367          0         22 ...         36         74         68]\n",
      " ...\n",
      " [3954827883          1         22 ...          4         20         54]\n",
      " [3954827882          1         22 ...         62          8         71]\n",
      " [3954827880          0         22 ...         35         27         17]]\n"
     ]
    }
   ],
   "source": [
    "m = np.loadtxt('dota_recent.txt', dtype=int)\n",
    "#m = m[ : 20000]\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_synnergy(lines):\n",
    "    matches_pairs = np.zeros((121, 121))\n",
    "    wins_pairs = np.zeros((121, 121)) \n",
    "    wr_pairs = np.zeros((121, 121))\n",
    "\n",
    "    for line in lines:\n",
    "        rad_wins = line[1] == 1\n",
    "        dire_wins = not rad_wins\n",
    "        heroes = line[3:]\n",
    "        rad = heroes[:5]\n",
    "        dire = heroes[5:]\n",
    "\n",
    "        for team in [rad, dire]:\n",
    "            for hero1 in team:\n",
    "                for hero2 in team:\n",
    "                    matches_pairs[hero1, hero2] += 1\n",
    "\n",
    "                    if rad_wins and hero1 in rad:\n",
    "                        wins_pairs[hero1, hero2] += 1 \n",
    "                    elif dire_wins and hero2 in dire:\n",
    "                        wins_pairs[hero1, hero2] += 1\n",
    "\n",
    "    matches_pairs[matches_pairs == 0] = 1\n",
    "    wr_pairs = wins_pairs / matches_pairs\n",
    "    return wr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_counters(lines):\n",
    "    matches_counter = np.zeros((121, 121))\n",
    "    wins_counter = np.zeros((121, 121)) \n",
    "    wr_counter = np.zeros((121, 121))\n",
    "\n",
    "    for line in lines:\n",
    "        rad_wins = line[1] == 1\n",
    "        dire_wins = not rad_wins\n",
    "        heroes = line[3:]\n",
    "        rad = heroes[:5]\n",
    "        dire = heroes[5:]\n",
    "\n",
    "        for hero1 in rad:\n",
    "            for hero2 in dire:\n",
    "                matches_counter[hero1, hero2] += 1\n",
    "                matches_counter[hero2, hero1] += 1\n",
    "                if rad_wins: wins_counter[hero1, hero2] += 1\n",
    "                else: wins_counter[hero2, hero1] += 1\n",
    "\n",
    "    wins_counter[matches_counter == 0] = 1\n",
    "    matches_counter[matches_counter == 0] = 1\n",
    "    wr_counter = wins_counter / matches_counter\n",
    "    return wr_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.shuffle(m)\n",
    "factor = 0.9\n",
    "train_size = int(len(m) * factor)\n",
    "wr_pairs = compute_synnergy(m[: train_size])\n",
    "wr_counters = compute_counters(m[ : train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wr_counters[50, 63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(lines):\n",
    "    #inputs = np.zeros((len(lines), 121+75))\n",
    "    inputs = np.zeros((len(lines), 121))\n",
    "    outputs = np.zeros((len(lines)))\n",
    "\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "        input = inputs[i]\n",
    "        outputs[i] = line[1]\n",
    "        game_type = line[2]\n",
    "        \n",
    "        heroes = line[3:]\n",
    "        rad = heroes[:5]\n",
    "        dire = heroes[5:]\n",
    "            \n",
    "        for hero in rad:\n",
    "            input[hero] = 1\n",
    "\n",
    "        for hero in dire:\n",
    "            input[hero] = -1\n",
    "            \n",
    "#         counter = 121\n",
    "        \n",
    "#         input[counter] = len([hero for hero in rad if hero in supps])\n",
    "#         counter += 1\n",
    "        \n",
    "#         input[counter] = len([hero for hero in dire if hero in supps])\n",
    "#         counter += 1\n",
    "        \n",
    "#         input[counter] = len([hero for hero in rad if hero in cores])\n",
    "#         counter += 1\n",
    "        \n",
    "#         input[counter] = len([hero for hero in dire if hero in cores])\n",
    "#         counter += 1\n",
    "        \n",
    "#         for team in [rad,dire]:\n",
    "#             for hero1 in team:\n",
    "#                 for hero2 in team:\n",
    "#                     input[counter] = wr_pairs[hero1, hero2]\n",
    "#                     counter += 1\n",
    "                    \n",
    "#         for hero1 in rad:\n",
    "#             for hero2 in dire:\n",
    "#                 input[counter] = wr_counters[hero1, hero2]\n",
    "#                 counter += 1\n",
    "\n",
    "    return (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " -1.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0. -1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = format_data(m)\n",
    "print(inputs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = inputs[10]\n",
    "#match[35] = 0\n",
    "print(len([v for v in match if v <= -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(inputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 4s 198us/step - loss: 0.6810 - binary_accuracy: 0.5695 - val_loss: 0.6658 - val_binary_accuracy: 0.5960\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 3s 190us/step - loss: 0.6690 - binary_accuracy: 0.5952 - val_loss: 0.6670 - val_binary_accuracy: 0.5935\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 3s 184us/step - loss: 0.6609 - binary_accuracy: 0.6062 - val_loss: 0.6729 - val_binary_accuracy: 0.5885\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 3s 189us/step - loss: 0.6560 - binary_accuracy: 0.6108 - val_loss: 0.6672 - val_binary_accuracy: 0.5970\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.6499 - binary_accuracy: 0.6204 - val_loss: 0.6700 - val_binary_accuracy: 0.5935\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 3s 193us/step - loss: 0.6441 - binary_accuracy: 0.6247 - val_loss: 0.6741 - val_binary_accuracy: 0.5865\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 3s 193us/step - loss: 0.6379 - binary_accuracy: 0.6342 - val_loss: 0.6782 - val_binary_accuracy: 0.5875\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 4s 200us/step - loss: 0.6299 - binary_accuracy: 0.6392 - val_loss: 0.6797 - val_binary_accuracy: 0.5845\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 4s 197us/step - loss: 0.6228 - binary_accuracy: 0.6452 - val_loss: 0.6811 - val_binary_accuracy: 0.5755\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 4s 197us/step - loss: 0.6130 - binary_accuracy: 0.6564 - val_loss: 0.6984 - val_binary_accuracy: 0.5795\n",
      "2000/2000 [==============================] - 0s 37us/step\n",
      "0.5795\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adagrad, Adam\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "limit = 20000\n",
    "# limit = len(inputs[])\n",
    "train_size = int(limit * 0.9)\n",
    "test_size = limit - train_size\n",
    "train_in = inputs[ : train_size]\n",
    "train_out = outputs[: train_size]\n",
    "test_in = inputs[train_size : limit]\n",
    "test_out = outputs[train_size : limit]\n",
    "\n",
    "model.add(Dense(10000, activation='relu', input_dim=len(inputs[0])))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.05)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              #optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              optimizer='adadelta',\n",
    "              #optimizer=sgd,\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(train_in, train_out,\n",
    "          epochs=10,\n",
    "          validation_data=(test_in, test_out))\n",
    "\n",
    "result = model.evaluate(test_in, test_out)\n",
    "\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_features=11, min_samples_split=2, max_depth=None, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(5, weights='uniform')\n",
    "clf = clf.fit(data['train']['in'], data['train']['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "# from sklearn import svm\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(data['train']['in'], data['train']['out'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=2000, learning_rate=1.0, max_depth=1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = BaggingClassifier(LogisticRegression(),\n",
    "                             max_samples=0.5, max_features=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf = VotingClassifier(estimators=[('for', clf_forest), ('naive', clf_naive), ('log', clf_log)], voting='soft', weights=[1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "clf = LogisticRegressionCV(Cs=10, solver='saga', cv=3, max_iter=1000, n_jobs=8, verbose=0, refit=True, intercept_scaling=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "# tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                      'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "tuned_parameters = [{'n_estimators': [10, 50, 100], 'max_features': [11, 40, 121]}]\n",
    "\n",
    "scores = ['precision']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % 'precision')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6045691248110197\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# print(inputs)\n",
    "# print(outputs)\n",
    "# limit = len(inputs)\n",
    "# scores = cross_val_score(clf, inputs, outputs, cv=5)\n",
    "\n",
    "train_size = int(len(inputs) * 0.9)\n",
    "test_size = len(inputs) - train_size\n",
    "\n",
    "\n",
    "\n",
    "clf = clf.fit(inputs[:train_size], outputs[:train_size])\n",
    "preds = clf.predict(inputs[train_size:])\n",
    "correct = outputs[train_size:]\n",
    "\n",
    "# print(scores)\n",
    "\n",
    "print(accuracy_score(correct, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "heroes = pd.read_csv('dota-2-match-prediction-master/data/MatchOverviewTraining.csv').values\n",
    "df_extra = pd.read_csv('dota-2-match-prediction-master/data/MatchDetail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(heroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(heroes, df_extra):\n",
    "    matches = np.zeros((10000, 121), dtype=int)\n",
    "    out = np.zeros((10000), dtype=int)\n",
    "    \n",
    "    for (i, line) in enumerate(heroes):\n",
    "        out[i] = 1 if line[-1] else 0\n",
    "        match_id = line[0]\n",
    "        heroes = line[1:]\n",
    "        rad = heroes[:5]\n",
    "        dire = heroes[5:-1]\n",
    "        \n",
    "        for hero in rad:\n",
    "            matches[i][hero] = 1\n",
    "            \n",
    "        for hero in dire:\n",
    "            matches[i][hero] = -1\n",
    "            \n",
    "        \n",
    "#         counter = 121\n",
    "        \n",
    "#         exp_gold = df_extra.loc[df_extra['match_id'] == match_id].values\n",
    "#         for (j, data) in enumerate(exp_gold):\n",
    "#             matches[i][counter + 2*j] = data[4]\n",
    "#             matches[i][counter + 2*j + 1] = data[14]\n",
    "            \n",
    "    return matches, out\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, output = gen_data(heroes, df_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adagrad, Adam\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "train_size = int(len(input) * 0.9)\n",
    "test_size = len(input) - train_size\n",
    "train_in = input[ : train_size]\n",
    "train_out = output[: train_size]\n",
    "test_in = input[train_size : ]\n",
    "test_out = output[train_size : ]\n",
    "\n",
    "model.add(Dense(100, activation='relu', input_dim=len(input[0])))\n",
    "#model.add(Dropout(0.1))\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#sgd = SGD(lr=0.05)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              #optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              optimizer='adadelta',\n",
    "              #optimizer=sgd,\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(train_in, train_out,\n",
    "          epochs=200,\n",
    "          validation_data=(test_in, test_out))\n",
    "\n",
    "result = model.evaluate(test_in, test_out)\n",
    "\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(input[0])\n",
    "clf.predict_proba([input[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6045691248110197\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# print(inputs)\n",
    "# print(outputs)\n",
    "#limit = len(inputs)\n",
    "#scores = cross_val_score(clf, inputs[:limit], outputs[:limit], cv=2)\n",
    "\n",
    "factor = 0.9\n",
    "train_size = int(len(inputs) * factor)\n",
    "test_size = len(inputs) - train_size\n",
    "train_in, train_out, test_in, test_out = inputs[:train_size], outputs[:train_size], inputs[train_size:], outputs[train_size:]\n",
    "\n",
    "# print(train_out, test_out)\n",
    "\n",
    "clf = clf.fit(train_in, train_out)\n",
    "preds = clf.predict(test_in)\n",
    "correct = test_out\n",
    "\n",
    "# print(scores)\n",
    "\n",
    "print(accuracy_score(correct, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rad: ['crystal_maiden', 'vengefulspirit', 'windrunner', 'bristleback']\n",
      "Dire: ['antimage', 'bloodseeker', 'zuus', 'lion', 'riki']\n",
      "[ 0. -1.  0.  0. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  1. -1.  0.  0.  0. -1.  0.  0.  0.  0.  0. -1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "match = inputs[0]\n",
    "print_heroes(match)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "match[114] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rad: ['crystal_maiden', 'vengefulspirit', 'windrunner', 'bristleback', 'monkey_king']\n",
      "Dire: ['bloodseeker', 'lion', 'riki']\n",
      "[ 0.  0.  0.  0. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  1.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0. -1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "match[22] = 0\n",
    "print_heroes(match)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chance: 0.437035 hero: axe\n",
      "chance: 0.318049 hero: bane\n",
      "chance: 0.404187 hero: drow_ranger\n",
      "chance: 0.376936 hero: earthshaker\n",
      "chance: 0.381940 hero: juggernaut\n",
      "chance: 0.385745 hero: mirana\n",
      "chance: 0.333265 hero: morphling\n",
      "chance: 0.310563 hero: nevermore\n",
      "chance: 0.403231 hero: phantom_lancer\n",
      "chance: 0.243094 hero: puck\n",
      "chance: 0.401993 hero: pudge\n",
      "chance: 0.317593 hero: razor\n",
      "chance: 0.326704 hero: sand_king\n",
      "chance: 0.347727 hero: storm_spirit\n",
      "chance: 0.371615 hero: sven\n",
      "chance: 0.254329 hero: tiny\n",
      "chance: 0.341037 hero: kunkka\n",
      "chance: 0.358562 hero: N/A\n",
      "chance: 0.298482 hero: lina\n",
      "chance: 0.380851 hero: shadow_shaman\n",
      "chance: 0.349853 hero: slardar\n",
      "chance: 0.369943 hero: tidehunter\n",
      "chance: 0.359329 hero: witch_doctor\n",
      "chance: 0.386526 hero: lich\n",
      "chance: 0.358071 hero: enigma\n",
      "chance: 0.330757 hero: tinker\n",
      "chance: 0.352275 hero: sniper\n",
      "chance: 0.392958 hero: necrolyte\n",
      "chance: 0.407136 hero: warlock\n",
      "chance: 0.355123 hero: beastmaster\n",
      "chance: 0.316088 hero: queenofpain\n",
      "chance: 0.353165 hero: venomancer\n",
      "chance: 0.374978 hero: faceless_void\n",
      "chance: 0.440794 hero: skeleton_king\n",
      "chance: 0.293934 hero: death_prophet\n",
      "chance: 0.385336 hero: phantom_assassin\n",
      "chance: 0.319085 hero: pugna\n",
      "chance: 0.295185 hero: templar_assassin\n",
      "chance: 0.346851 hero: viper\n",
      "chance: 0.398725 hero: luna\n",
      "chance: 0.394480 hero: dragon_knight\n",
      "chance: 0.361945 hero: dazzle\n",
      "chance: 0.401727 hero: rattletrap\n",
      "chance: 0.301320 hero: leshrac\n",
      "chance: 0.285426 hero: furion\n",
      "chance: 0.332254 hero: life_stealer\n",
      "chance: 0.344916 hero: dark_seer\n",
      "chance: 0.393631 hero: clinkz\n",
      "chance: 0.385707 hero: omniknight\n",
      "chance: 0.304170 hero: enchantress\n",
      "chance: 0.350947 hero: huskar\n",
      "chance: 0.388601 hero: night_stalker\n",
      "chance: 0.313671 hero: broodmother\n",
      "chance: 0.347979 hero: bounty_hunter\n",
      "chance: 0.355896 hero: weaver\n",
      "chance: 0.361876 hero: jakiro\n",
      "chance: 0.305752 hero: batrider\n",
      "chance: 0.378132 hero: chen\n",
      "chance: 0.484556 hero: spectre\n",
      "chance: 0.391146 hero: ancient_apparition\n",
      "chance: 0.367816 hero: doom_bringer\n",
      "chance: 0.398008 hero: ursa\n",
      "chance: 0.425792 hero: spirit_breaker\n",
      "chance: 0.303762 hero: gyrocopter\n",
      "chance: 0.338338 hero: alchemist\n",
      "chance: 0.357988 hero: invoker\n",
      "chance: 0.389605 hero: silencer\n",
      "chance: 0.285284 hero: obsidian_destroyer\n",
      "chance: 0.399855 hero: lycan\n",
      "chance: 0.379584 hero: brewmaster\n",
      "chance: 0.333827 hero: shadow_demon\n",
      "chance: 0.274586 hero: lone_druid\n",
      "chance: 0.433075 hero: chaos_knight\n",
      "chance: 0.333197 hero: meepo\n",
      "chance: 0.408418 hero: treant\n",
      "chance: 0.395734 hero: ogre_magi\n",
      "chance: 0.420576 hero: undying\n",
      "chance: 0.332826 hero: rubick\n",
      "chance: 0.334696 hero: disruptor\n",
      "chance: 0.366385 hero: nyx_assassin\n",
      "chance: 0.305618 hero: naga_siren\n",
      "chance: 0.345066 hero: keeper_of_the_light\n",
      "chance: 0.265964 hero: wisp\n",
      "chance: 0.396749 hero: visage\n",
      "chance: 0.388997 hero: slark\n",
      "chance: 0.355408 hero: medusa\n",
      "chance: 0.372220 hero: troll_warlord\n",
      "chance: 0.426604 hero: centaur\n",
      "chance: 0.324019 hero: magnataur\n",
      "chance: 0.320600 hero: shredder\n",
      "chance: 0.325171 hero: tusk\n",
      "chance: 0.358284 hero: skywrath_mage\n",
      "chance: 0.392133 hero: abaddon\n",
      "chance: 0.405250 hero: elder_titan\n",
      "chance: 0.340195 hero: legion_commander\n",
      "chance: 0.355314 hero: techies\n",
      "chance: 0.345898 hero: ember_spirit\n",
      "chance: 0.306455 hero: earth_spirit\n",
      "chance: 0.425327 hero: abyssal_underlord\n",
      "chance: 0.367378 hero: terrorblade\n",
      "chance: 0.417817 hero: phoenix\n",
      "chance: 0.337871 hero: oracle\n",
      "chance: 0.373307 hero: winter_wyvern\n",
      "chance: 0.354731 hero: arc_warden\n",
      "chance: 0.327443 hero: monkey_king\n",
      "chance: 0.358562 hero: N/A\n",
      "chance: 0.358562 hero: N/A\n",
      "chance: 0.358562 hero: N/A\n",
      "chance: 0.358562 hero: N/A\n",
      "chance: 0.348858 hero: dark_willow\n",
      "BEST: spectre\n",
      "Rad: ['crystal_maiden', 'vengefulspirit', 'windrunner', 'bristleback']\n",
      "Dire: ['antimage', 'bloodseeker', 'zuus', 'lion', 'riki']\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "best_chance = 0\n",
    "\n",
    "for i in range(120):\n",
    "    if match[i] != 0: continue\n",
    "    match[i] = 1\n",
    "    chance_win = clf.predict_proba([match])[0][1]\n",
    "    \n",
    "    if chance_win > best_chance:\n",
    "        best_chance = chance_win\n",
    "        best = i\n",
    "        \n",
    "    print('chance: %f hero: %s' % (chance_win, idToHero.get(i, \"N/A\")))\n",
    "    match[i] = 0\n",
    "\n",
    "print('BEST:', idToHero[best])\n",
    "match[0] = 0\n",
    "print_heroes(match)\n",
    "\n",
    "# print(len([v for v in match if v != 0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
