{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sups = [7, 23, 57, 83, 91, 110, 9, 20, 89, 5, 21, 25, 27, 58, 64, 66, 75, 84, 86, 87, 90, 101, 111, 119, 16, 42, \n",
    "         85, 102, 108, 40, 3, 31, 26, 30, 37, 50, 52, 68, 79, 92, 112]\n",
    "\n",
    "cores = [18, 19, 23, 49, 59, 73, 78, 99, 104, 1, 6, 8, 9, 10, 12, 32, 35, 46, 48, 70, 72, 80, 89, 95, 106, 114, \n",
    "         120, 17, 21, 25, 34, 53, 75, 28, 42, 54, 60, 69, 71, 77, 81, 102, 4, 11, 15, 41, 44, 47, 56, 61, 63, 67, \n",
    "         82, 93, 94, 109, 113, 36, 39, 43, 52, 74, 76]\n",
    "\n",
    "idToHero = {1: 'antimage', 2: 'axe', 3: 'bane', 4: 'bloodseeker', 5: 'crystal_maiden', 6: 'drow_ranger', \n",
    "            7: 'earthshaker', 8: 'juggernaut', 9: 'mirana', 11: 'nevermore', 10: 'morphling', 12: 'phantom_lancer', \n",
    "            13: 'puck', 14: 'pudge', 15: 'razor', 16: 'sand_king', 17: 'storm_spirit', 18: 'sven', 19: 'tiny', \n",
    "            20: 'vengefulspirit', 21: 'windrunner', 22: 'zuus', 23: 'kunkka', 25: 'lina', 31: 'lich', 26: 'lion', \n",
    "            27: 'shadow_shaman', 28: 'slardar', 29: 'tidehunter', 30: 'witch_doctor', 32: 'riki', 33: 'enigma', \n",
    "            34: 'tinker', 35: 'sniper', 36: 'necrolyte', 37: 'warlock', 38: 'beastmaster', 39: 'queenofpain', \n",
    "            40: 'venomancer', 41: 'faceless_void', 42: 'skeleton_king', 43: 'death_prophet', 44: 'phantom_assassin',\n",
    "            45: 'pugna', 46: 'templar_assassin', 47: 'viper', 48: 'luna', 49: 'dragon_knight', 50: 'dazzle', 51: \n",
    "            'rattletrap', 52: 'leshrac', 53: 'furion', 54: 'life_stealer', 55: 'dark_seer', 56: 'clinkz', \n",
    "            57: 'omniknight', 58: 'enchantress', 59: 'huskar', 60: 'night_stalker', 61: 'broodmother', \n",
    "            62: 'bounty_hunter', 63: 'weaver', 64: 'jakiro', 65: 'batrider', 66: 'chen', 67: 'spectre', \n",
    "            69: 'doom_bringer', 68: 'ancient_apparition', 70: 'ursa', 71: 'spirit_breaker', 72: 'gyrocopter', \n",
    "            73: 'alchemist', 74: 'invoker', 75: 'silencer', 76: 'obsidian_destroyer', 77: 'lycan', \n",
    "            78: 'brewmaster', 79: 'shadow_demon', 80: 'lone_druid', 81: 'chaos_knight', 82: 'meepo', 83: 'treant', \n",
    "            84: 'ogre_magi', 85: 'undying', 86: 'rubick', 87: 'disruptor', 88: 'nyx_assassin', 89: 'naga_siren', \n",
    "            90: 'keeper_of_the_light', 91: 'wisp', 92: 'visage', 93: 'slark', 94: 'medusa', 95: 'troll_warlord', \n",
    "            96: 'centaur', 97: 'magnataur', 98: 'shredder', 99: 'bristleback', 100: 'tusk', 101: 'skywrath_mage', \n",
    "            102: 'abaddon', 103: 'elder_titan', 104: 'legion_commander', 106: 'ember_spirit', 107: 'earth_spirit', \n",
    "            109: 'terrorblade', 110: 'phoenix', 111: 'oracle', 105: 'techies', 112: 'winter_wyvern', \n",
    "            113: 'arc_warden', 108: 'abyssal_underlord', 114: 'monkey_king', 120: 'pangolier', 119: 'dark_willow'}\n",
    "\n",
    "import time\n",
    "\n",
    "#mirana=9, bane=4 sinergia=0.0315556044752\n",
    "#faceless void=41, phantom assassin=44 sinergia=-0.0205830863765\n",
    "# earthshaker=7, phantom lancer=12\n",
    "\n",
    "\n",
    "\n",
    "print(len(supps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0545901751471\n",
      "[(0.48900262245156922, 7), (0.46672439017108053, 23), (0.51391769457482805, 57), (0.53612167300380231, 83), (0.4004744958481613, 91), (0.54376556215284433, 110), (0.51600393125614263, 9), (0.54798683210939481, 20), (0.45394363533194626, 89), (0.53160188101298589, 5), (0.48386816999132698, 21), (0.43096253926578837, 25), (0.51713284212032329, 27), (0.45039018952062432, 58), (0.49843937575030012, 64), (0.48002049180327871, 66), (0.52119328032522272, 75), (0.52144590004852009, 84), (0.45219983552631576, 86), (0.46994274809160308, 87), (0.47601615753597576, 90), (0.49938583321959873, 101), (0.46433483985065827, 111), (0.48744419642857145, 119), (0.45695005121407484, 16), (0.5539981044545319, 42), (0.54382451120648545, 85), (0.52095808383233533, 102), (0.55081085486105452, 108), (0.47657605552342397, 40), (0.46423864861626934, 3), (0.52754982415005858, 31), (0.4826878377154587, 26), (0.49189054726368159, 30), (0.55118408588569623, 37), (0.49245999769770921, 50), (0.44870283018867924, 52), (0.52440796785500554, 68), (0.46977730646871685, 79), (0.51455503188245078, 92), (0.48709219858156028, 112)]\n"
     ]
    }
   ],
   "source": [
    "print(wr_counters[7,12] - wr_counters[12,7] - wr_pairs[7,7] + wr_pairs[12,12])\n",
    "\n",
    "# print(syn_table\n",
    "#       [41,44])\n",
    "\n",
    "winrates = [(wr_pairs[hero, hero], hero) for hero in sups]\n",
    "print(winrates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.524457549319\n",
      "['morphling', 'lycan', 'centaur', 'earthshaker', 'skywrath_mage']\n",
      "['slark', 'shadow_shaman', 'pudge', 'dragon_knight', 'abyssal_underlord']\n"
     ]
    }
   ],
   "source": [
    "bom1 = [10, 77, 96, 7, 101]\n",
    "bom2 = [93, 27, 14, 49, 108]\n",
    "\n",
    "\n",
    "# winrates.sort()\n",
    "# print(winrates)\n",
    "\n",
    "# print(idToHero[winrates[-6][1]], winrates[-6][1])\n",
    "# print(idToHero[winrates[-7][1]], winrates[-7][1])\n",
    "# print(idToHero[winrates[-8][1]], winrates[-8][1])\n",
    "# print(idToHero[winrates[-4][1]], winrates[-4][1])\n",
    "# print(idToHero[winrates[-9][1]], winrates[-9][1])\n",
    "\n",
    "\n",
    "# sups = [110,83,5,20,31]\n",
    "\n",
    "\n",
    "# time1 = [1, 60, 83, 85, 43]\n",
    "# time2 = [17, 42, 108, 68, 31]\n",
    "# # heroes = [71,42,6,81,4]\n",
    "winrate = [wr_pairs[hero, hero] for hero in bom2]\n",
    "avg = np.mean(winrate)\n",
    "print(avg)\n",
    "\n",
    "# sups = [110, 37, 83, 20, 5]\n",
    "# cores = [71,42,6,81,4]\n",
    "\n",
    "# time bom: Morphling, Lycanthrope, Centaur, Elder Titan e Skywrath Mage\n",
    "\n",
    "# time pain: Morphling, Ember Spirit, Warlock, Omniknight e Tusk\n",
    "# pain = [10, 106, 37, 57, 100]\n",
    "\n",
    "print([idToHero[id] for id in bom1])\n",
    "print([idToHero[id] for id in bom2])\n",
    "# print([idToHero[id] for id in time2])\n",
    "\n",
    "#time 1: Anti-Mage, Night Stalker, Treant, Undying e Death Prophet\n",
    "#time 2: Storm Spirit, Wraith King, Underlord, Ancient Apparation e Lich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ember_spirit', 'lycan', 'centaur', 'earthshaker', 'skywrath_mage']\n",
      "['slark', 'shadow_shaman', 'pudge', 'dragon_knight', 'bristleback']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.4253781,  0.5746219]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_input(rad, dire):\n",
    "    input = np.zeros((121 + 75))\n",
    "    for hero in  rad:\n",
    "        input[hero] = 1\n",
    "    for hero in dire:\n",
    "        input[hero] = -1\n",
    "    \n",
    "    counter = 121\n",
    "    \n",
    "    for hero1 in rad:\n",
    "            for hero2 in rad:\n",
    "                input[counter] = wr_pairs[hero1, hero2]\n",
    "                counter += 1\n",
    "              \n",
    "  \n",
    "    for hero1 in dire:\n",
    "            for hero2 in dire:\n",
    "                input[counter] = -wr_pairs[hero1, hero2]\n",
    "                counter += 1\n",
    "   \n",
    "    for hero1 in rad:\n",
    "            for hero2 in dire:\n",
    "                input[counter] = wr_counters[hero1, hero2]\n",
    "                counter += 1\n",
    "                \n",
    "    return [input]\n",
    "\n",
    "bom1 = [106, 77, 96, 7, 101]\n",
    "bom2 = [93, 27, 14, 49, 99]\n",
    "\n",
    "\n",
    "print([idToHero[id] for id in bom1])\n",
    "print([idToHero[id] for id in bom2])\n",
    "\n",
    "clf.predict_proba(gen_input(bom1, bom2))\n",
    "\n",
    "#0.74432872\n",
    "#0.79667151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiny', 'puck', 'lone_druid', 'oracle', 'centaur']\n"
     ]
    }
   ],
   "source": [
    "bom1 = []\n",
    "bom2_correct = [93, 27, 14, 49, 99]\n",
    "bom2 = []\n",
    "\n",
    "def add_new_hero(bom1, bom2):\n",
    "    i = len(bom1)\n",
    "    bom2.append(bom2_correct[i])\n",
    "    \n",
    "    \n",
    "    bom1.append(-1)\n",
    "    \n",
    "    best_hero = -1\n",
    "    best_chance = 0\n",
    "    \n",
    "    for hero in range(121):\n",
    "        hero_name = idToHero.get(hero, \"undefined\")\n",
    "        if hero in bom1 or hero in bom2 or hero_name == \"undefined\": continue\n",
    "            \n",
    "        bom1[i] = hero\n",
    "        input = gen_input(bom1, bom2)\n",
    "        win_chance = clf.predict_proba(input)[0][1]\n",
    "            \n",
    "        if win_chance > best_chance:\n",
    "            best_hero = hero\n",
    "            best_chance = win_chance\n",
    "    \n",
    "    bom1[i] = best_hero\n",
    "    \n",
    "add_new_hero(bom1, bom2)\n",
    "add_new_hero(bom1, bom2)\n",
    "add_new_hero(bom1, bom2)\n",
    "add_new_hero(bom1, bom2)\n",
    "add_new_hero(bom1, bom2)\n",
    "print([idToHero.get(hero, \"undefined\") for hero in bom1])\n",
    "            \n",
    "\n",
    "# input = gen_input(bom1, bom2)\n",
    "# win_chance = clf.predict_proba(input)[0][1]\n",
    "# print('CHANCE: ', win_chance)\n",
    "\n",
    "# # best = []\n",
    "\n",
    "\n",
    "# for hero in range(121):\n",
    "#     if hero in bom1 or hero in bom2: continue\n",
    "#     bom1[3] = hero\n",
    "#     input = gen_input(bom1, bom2)\n",
    "#     win_chance = clf.predict_proba(input)[0][1]\n",
    "#     hero_name = idToHero.get(hero, \"undefined\")\n",
    "#     if hero_name != \"undefined\":\n",
    "#         best.append((win_chance, hero_name))\n",
    "    \n",
    "# best.sort()\n",
    "# print(best[-10:])\n",
    "# print([idToHero[id] for id in bom1])\n",
    "# print([idToHero[id] for id in bom2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_heroes(match):\n",
    "    rad = [id for (id, team) in enumerate(match) if team == 1]\n",
    "    dire = [id for (id, team) in enumerate(match) if team == -1]\n",
    "    print('Rad:', [idToHero[id] for id in rad])\n",
    "    print('Dire:', [idToHero[id] for id in dire])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.loadtxt('dota_recent_new.txt', dtype=np.int64)\n",
    "# m = m[ : 50000]\n",
    "# print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_synnergy(lines):\n",
    "    matches_pairs = np.zeros((121, 121))\n",
    "    wins_pairs = np.zeros((121, 121)) \n",
    "    wr_pairs = np.zeros((121, 121))\n",
    "\n",
    "    for line in lines:\n",
    "        rad_wins = line[1] == 1\n",
    "        dire_wins = not rad_wins\n",
    "        heroes = line[3:]\n",
    "        rad = heroes[:5]\n",
    "        dire = heroes[5:]\n",
    "\n",
    "        for team in [rad, dire]:\n",
    "            for hero1 in team:\n",
    "                for hero2 in team:\n",
    "                    matches_pairs[hero1, hero2] += 1\n",
    "\n",
    "                    if rad_wins and hero1 in rad:\n",
    "                        wins_pairs[hero1, hero2] += 1 \n",
    "                    elif dire_wins and hero2 in dire:\n",
    "                        wins_pairs[hero1, hero2] += 1\n",
    "\n",
    "    matches_pairs[matches_pairs == 0] = 1\n",
    "    wr_pairs = wins_pairs / matches_pairs\n",
    "    return wr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syn():\n",
    "    syn_table = np.zeros((121, 121))\n",
    "    \n",
    "    for hero1 in range(121):\n",
    "        for hero2 in range(121):\n",
    "            syn_table[hero1, hero2] = wr_pairs[hero1, hero2] - (wr_pairs[hero1, hero1] + wr_pairs[hero2, hero2]) / 2\n",
    "            \n",
    "    return syn_table\n",
    "\n",
    "syn_table = syn()\n",
    "print(syn_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes = [(syn_table[hero1, hero2], (idToHero.get(hero1, \"undefined\"), idToHero.get(hero2, \"undefined\"))) for hero1 in range(121) for hero2 in range(121) if hero1 < hero2]\n",
    "heroes.sort()\n",
    "print(heroes[-10:])\n",
    "\n",
    "\n",
    "# def choose_best(table):\n",
    "#     best_heroes = [(-1,-1)\n",
    "#     val = 0\n",
    "    \n",
    "#     for hero1 in range(121):\n",
    "#         for hero2 in range(121):\n",
    "#             if table[hero1, hero2] > val:\n",
    "#                 val = table[hero1, hero2]\n",
    "#                 best_heroes = (hero1, hero2)\n",
    "            \n",
    "#     return best_heroes\n",
    "\n",
    "# hero1, hero2 = choose_best(syn_table)\n",
    "# print(idToHero[hero1],idToHero[hero2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_counters(lines):\n",
    "    matches_counter = np.zeros((121, 121))\n",
    "    wins_counter = np.zeros((121, 121)) \n",
    "    wr_counter = np.zeros((121, 121))\n",
    "\n",
    "    for line in lines:\n",
    "        rad_wins = line[1] == 1\n",
    "        dire_wins = not rad_wins\n",
    "        heroes = line[3:]\n",
    "        rad = heroes[:5]\n",
    "        dire = heroes[5:]\n",
    "\n",
    "        for hero1 in rad:\n",
    "            for hero2 in dire:\n",
    "                matches_counter[hero1, hero2] += 1\n",
    "                matches_counter[hero2, hero1] += 1\n",
    "                if rad_wins: wins_counter[hero1, hero2] += 1\n",
    "                else: wins_counter[hero2, hero1] += 1\n",
    "\n",
    "    wins_counter[matches_counter == 0] = 1\n",
    "    matches_counter[matches_counter == 0] = 1\n",
    "    wr_counter = wins_counter / matches_counter\n",
    "    return wr_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.shuffle(m)\n",
    "factor = 1\n",
    "train_size = int(len(m) * factor)\n",
    "wr_pairs = compute_synnergy(m[: train_size])\n",
    "wr_counters = compute_counters(m[ : train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wr_counters[50, 63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(lines):\n",
    "#     inputs = np.zeros((len(lines), 121))\n",
    "    inputs = np.zeros((len(lines), 121+75))\n",
    "    outputs = np.zeros((len(lines)))\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        counter = 0\n",
    "        \n",
    "        line = lines[i]\n",
    "        input = inputs[i]\n",
    "        outputs[i] = line[1]\n",
    "        game_type = line[2]\n",
    "        \n",
    "        heroes = line[3:]\n",
    "        rad = heroes[:5]\n",
    "        dire = heroes[5:]\n",
    "        \n",
    "        for hero in rad:\n",
    "            input[hero] = 1\n",
    "\n",
    " \n",
    "        for hero in dire:\n",
    "            input[hero] = -1\n",
    "            \n",
    "        counter = 121    \n",
    "        \n",
    "        for hero1 in rad:\n",
    "            for hero2 in rad:\n",
    "                input[counter] = wr_pairs[hero1, hero2]\n",
    "                counter += 1\n",
    "              \n",
    "  \n",
    "        for hero1 in dire:\n",
    "                for hero2 in dire:\n",
    "                    input[counter] = -wr_pairs[hero1, hero2]\n",
    "                    counter += 1\n",
    "\n",
    "        for hero1 in rad:\n",
    "                for hero2 in dire:\n",
    "                    input[counter] = wr_counters[hero1, hero2]\n",
    "                    counter += 1\n",
    "\n",
    "\n",
    "    return (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -1.          0.          0.         -1.          1.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          1.\n",
      "  1.         -1.          0.          0.          0.         -1.          0.\n",
      "  0.          0.          0.          0.         -1.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          1.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          1.          0.          0.          0.          0.\n",
      "  0.          0.          0.5269389   0.56936648  0.49552773  0.57556008\n",
      "  0.49619079  0.56936648  0.54798683  0.49414824  0.54525862  0.53948242\n",
      "  0.49552773  0.49414824  0.4467994   0.47187238  0.43978827  0.57556008\n",
      "  0.54525862  0.47187238  0.53160188  0.51427256  0.49619079  0.53948242\n",
      "  0.43978827  0.51427256  0.48386817 -0.50339426 -0.5028647  -0.54457694\n",
      " -0.58815959 -0.58710407 -0.5028647  -0.48268784 -0.53679492 -0.57904085\n",
      " -0.55108878 -0.54457694 -0.53679492 -0.5476554  -0.63008596 -0.59803503\n",
      " -0.58815959 -0.57904085 -0.63008596 -0.58422033 -0.65809769 -0.58710407\n",
      " -0.55108878 -0.59803503 -0.65809769 -0.55119448  0.49678899  0.53888318\n",
      "  0.46299435  0.4406241   0.51122195  0.53623188  0.56237078  0.50421456\n",
      "  0.45593108  0.49910394  0.47457627  0.46275395  0.41785252  0.34971727\n",
      "  0.39570017  0.544375    0.54882899  0.48300355  0.44910462  0.48806683\n",
      "  0.48367136  0.5119557   0.43098266  0.38931145  0.42793329]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs, outputs = format_data(m)\n",
    "#print(len(inputs))\n",
    "print(inputs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = inputs[10]\n",
    "#match[35] = 0\n",
    "print(len([v for v in match if v <= -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adagrad, Adam\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# limit = 20000\n",
    "limit = len(inputs)\n",
    "train_size = int(limit * 0.9)\n",
    "test_size = limit - train_size\n",
    "train_in = inputs[ : train_size]\n",
    "train_out = outputs[: train_size]\n",
    "test_in = inputs[train_size : limit]\n",
    "test_out = outputs[train_size : limit]\n",
    "\n",
    "model.add(Dense(10000, activation='relu', input_dim=len(inputs[0])))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.05)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              #optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "#               optimizer='adadelta',\n",
    "              optimizer=sgd,\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "\n",
    "model.fit(train_in, train_out,\n",
    "          epochs=20,\n",
    "          validation_data=(test_in, test_out))\n",
    "\n",
    "\n",
    "result = model.evaluate(test_in, test_out)\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200, max_features=11, min_samples_split=2, max_depth=None, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(5, weights='distance', n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "# from sklearn import svm\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(data['train']['in'], data['train']['out'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=2000, learning_rate=1.0, max_depth=1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = BaggingClassifier(LogisticRegression(),\n",
    "                             max_samples=0.5, max_features=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf = VotingClassifier(estimators=[('for', clf_forest), ('naive', clf_naive), ('log', clf_log)], voting='soft', weights=[1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline:\n",
    "    def fit(inputs, outputs):\n",
    "        pass\n",
    "    \n",
    "    def _pred(self, input):\n",
    "        rad = []\n",
    "        dire = []\n",
    "        \n",
    "        for hero_id, val in enumerate(input):\n",
    "            if val == 1: rad.append(hero_id)\n",
    "            elif val == -1: dire.append(hero_id)\n",
    "          \n",
    "#         sinergy_rad = np.average([wr_pairs[hero, hero] for hero in rad])\n",
    "#         sinergy_dire = np.average([wr_pairs[hero, hero] for hero in dire])\n",
    "        \n",
    "        sinergy_rad = np.average([wr_pairs[hero1, hero2] for hero2 in rad for hero1 in rad])\n",
    "        sinergy_dire = np.average([wr_pairs[hero1, hero2] for hero2 in dire for hero1 in dire])\n",
    "        \n",
    "        #print(sinergy_dire)\n",
    "        \n",
    "        return 1 if sinergy_rad > sinergy_dire else 0\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        return [self._pred(input) for input in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Baseline()\n",
    "\n",
    "pred = x.predict(inputs[train_size:])\n",
    "correct = outputs[train_size:]\n",
    "\n",
    "right = 0\n",
    "\n",
    "for p,c in zip(pred,correct):\n",
    "    if p == c:\n",
    "        right += 1\n",
    "\n",
    "print(right / len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [74.4, 69.5, 63.5, 69.0, 74.5, 52.3, 71.7, 68.6, 59.2]\n",
    "print([0.93 * val for val in vals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "clf = LogisticRegressionCV(cv=5, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_size = int(len(inputs) * 0.9)\n",
    "test_size = len(inputs) - train_size\n",
    "\n",
    "clf = clf.fit(inputs[:train_size], outputs[:train_size])\n",
    "preds = clf.predict(inputs[train_size:])\n",
    "correct = outputs[train_size:]\n",
    "\n",
    "\n",
    "print(accuracy_score(correct, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "heroes = pd.read_csv('dota-2-match-prediction-master/data/MatchOverviewTraining.csv').values\n",
    "df_extra = pd.read_csv('dota-2-match-prediction-master/data/MatchDetail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(heroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(heroes, df_extra):\n",
    "    matches = np.zeros((10000, 121), dtype=int)\n",
    "    out = np.zeros((10000), dtype=int)\n",
    "    \n",
    "    for (i, line) in enumerate(heroes):\n",
    "        out[i] = 1 if line[-1] else 0\n",
    "        match_id = line[0]\n",
    "        heroes = line[1:]\n",
    "        rad = heroes[:5]\n",
    "        dire = heroes[5:-1]\n",
    "        \n",
    "        for hero in rad:\n",
    "            matches[i][hero] = 1\n",
    "            \n",
    "        for hero in dire:\n",
    "            matches[i][hero] = -1\n",
    "            \n",
    "        \n",
    "#         counter = 121\n",
    "        \n",
    "#         exp_gold = df_extra.loc[df_extra['match_id'] == match_id].values\n",
    "#         for (j, data) in enumerate(exp_gold):\n",
    "#             matches[i][counter + 2*j] = data[4]\n",
    "#             matches[i][counter + 2*j + 1] = data[14]\n",
    "            \n",
    "    return matches, out\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, output = gen_data(heroes, df_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adagrad, Adam\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "train_size = int(len(input) * 0.9)\n",
    "test_size = len(input) - train_size\n",
    "train_in = input[ : train_size]\n",
    "train_out = output[: train_size]\n",
    "test_in = input[train_size : ]\n",
    "test_out = output[train_size : ]\n",
    "\n",
    "model.add(Dense(100, activation='relu', input_dim=len(input[0])))\n",
    "#model.add(Dropout(0.1))\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#sgd = SGD(lr=0.05)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              #optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              optimizer='adadelta',\n",
    "              #optimizer=sgd,\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(train_in, train_out,\n",
    "          epochs=200,\n",
    "          validation_data=(test_in, test_out))\n",
    "\n",
    "result = model.evaluate(test_in, test_out)\n",
    "\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(input[0])\n",
    "clf.predict_proba([input[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "factor = 0.9\n",
    "train_size = int(len(inputs) * factor)\n",
    "test_size = len(inputs) - train_size\n",
    "train_in, train_out, test_in, test_out = inputs[:train_size], outputs[:train_size], inputs[train_size:], outputs[train_size:]\n",
    "\n",
    "\n",
    "clf = clf.fit(train_in, train_out)\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "preds = clf.predict(test_in)\n",
    "correct = test_out\n",
    "\n",
    "print(accuracy_score(correct, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = inputs[0]\n",
    "print_heroes(match)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match[114] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match[22] = 0\n",
    "print_heroes(match)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 0\n",
    "best_chance = 0\n",
    "\n",
    "for i in range(120):\n",
    "    if match[i] != 0: continue\n",
    "    match[i] = 1\n",
    "    chance_win = clf.predict_proba([match])[0][1]\n",
    "    \n",
    "    if chance_win > best_chance:\n",
    "        best_chance = chance_win\n",
    "        best = i\n",
    "        \n",
    "    print('chance: %f hero: %s' % (chance_win, idToHero.get(i, \"N/A\")))\n",
    "    match[i] = 0\n",
    "\n",
    "print('BEST:', idToHero[best])\n",
    "match[0] = 0\n",
    "print_heroes(match)\n",
    "\n",
    "# print(len([v for v in match if v != 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "# tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                      'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "tuned_parameters = [{'n_estimators': [10, 50, 100], 'max_features': [11, 40, 121]}]\n",
    "\n",
    "scores = ['precision']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % 'precision')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
