{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sups = [7, 23, 57, 83, 91, 110, 9, 20, 89, 5, 21, 25, 27, 58, 64, 66, 75, 84, 86, 87, 90, 101, 111, 119, 16, 42, \n",
    "         85, 102, 108, 40, 3, 31, 26, 30, 37, 50, 52, 68, 79, 92, 112]\n",
    "\n",
    "cores = [18, 19, 23, 49, 59, 73, 78, 99, 104, 1, 6, 8, 9, 10, 12, 32, 35, 46, 48, 70, 72, 80, 89, 95, 106, 114, \n",
    "         120, 17, 21, 25, 34, 53, 75, 28, 42, 54, 60, 69, 71, 77, 81, 102, 4, 11, 15, 41, 44, 47, 56, 61, 63, 67, \n",
    "         82, 93, 94, 109, 113, 36, 39, 43, 52, 74, 76]\n",
    "\n",
    "idToHero = {1: 'antimage', 2: 'axe', 3: 'bane', 4: 'bloodseeker', 5: 'crystal_maiden', 6: 'drow_ranger', \n",
    "            7: 'earthshaker', 8: 'juggernaut', 9: 'mirana', 11: 'nevermore', 10: 'morphling', 12: 'phantom_lancer', \n",
    "            13: 'puck', 14: 'pudge', 15: 'razor', 16: 'sand_king', 17: 'storm_spirit', 18: 'sven', 19: 'tiny', \n",
    "            20: 'vengefulspirit', 21: 'windrunner', 22: 'zuus', 23: 'kunkka', 25: 'lina', 31: 'lich', 26: 'lion', \n",
    "            27: 'shadow_shaman', 28: 'slardar', 29: 'tidehunter', 30: 'witch_doctor', 32: 'riki', 33: 'enigma', \n",
    "            34: 'tinker', 35: 'sniper', 36: 'necrolyte', 37: 'warlock', 38: 'beastmaster', 39: 'queenofpain', \n",
    "            40: 'venomancer', 41: 'faceless_void', 42: 'skeleton_king', 43: 'death_prophet', 44: 'phantom_assassin',\n",
    "            45: 'pugna', 46: 'templar_assassin', 47: 'viper', 48: 'luna', 49: 'dragon_knight', 50: 'dazzle', 51: \n",
    "            'rattletrap', 52: 'leshrac', 53: 'furion', 54: 'life_stealer', 55: 'dark_seer', 56: 'clinkz', \n",
    "            57: 'omniknight', 58: 'enchantress', 59: 'huskar', 60: 'night_stalker', 61: 'broodmother', \n",
    "            62: 'bounty_hunter', 63: 'weaver', 64: 'jakiro', 65: 'batrider', 66: 'chen', 67: 'spectre', \n",
    "            69: 'doom_bringer', 68: 'ancient_apparition', 70: 'ursa', 71: 'spirit_breaker', 72: 'gyrocopter', \n",
    "            73: 'alchemist', 74: 'invoker', 75: 'silencer', 76: 'obsidian_destroyer', 77: 'lycan', \n",
    "            78: 'brewmaster', 79: 'shadow_demon', 80: 'lone_druid', 81: 'chaos_knight', 82: 'meepo', 83: 'treant', \n",
    "            84: 'ogre_magi', 85: 'undying', 86: 'rubick', 87: 'disruptor', 88: 'nyx_assassin', 89: 'naga_siren', \n",
    "            90: 'keeper_of_the_light', 91: 'wisp', 92: 'visage', 93: 'slark', 94: 'medusa', 95: 'troll_warlord', \n",
    "            96: 'centaur', 97: 'magnataur', 98: 'shredder', 99: 'bristleback', 100: 'tusk', 101: 'skywrath_mage', \n",
    "            102: 'abaddon', 103: 'elder_titan', 104: 'legion_commander', 106: 'ember_spirit', 107: 'earth_spirit', \n",
    "            109: 'terrorblade', 110: 'phoenix', 111: 'oracle', 105: 'techies', 112: 'winter_wyvern', \n",
    "            113: 'arc_warden', 108: 'abyssal_underlord', 114: 'monkey_king', 120: 'pangolier', 119: 'dark_willow'}\n",
    "\n",
    "import time\n",
    "\n",
    "#mirana=9, bane=4 sinergia=0.0315556044752\n",
    "#faceless void=41, phantom assassin=44 sinergia=-0.0205830863765\n",
    "# earthshaker=7, phantom lancer=12\n",
    "\n",
    "\n",
    "\n",
    "print(len(sups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wr_counters[7,12] - wr_counters[12,7] - wr_pairs[7,7] + wr_pairs[12,12])\n",
    "\n",
    "# print(syn_table\n",
    "#       [41,44])\n",
    "\n",
    "winrates = [(wr_pairs[hero, hero], hero) for hero in sups]\n",
    "print(winrates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bom1 = [10, 77, 96, 7, 101]\n",
    "bom2 = [93, 27, 14, 49, 108]\n",
    "\n",
    "\n",
    "# winrates.sort()\n",
    "# print(winrates)\n",
    "\n",
    "# print(idToHero[winrates[-6][1]], winrates[-6][1])\n",
    "# print(idToHero[winrates[-7][1]], winrates[-7][1])\n",
    "# print(idToHero[winrates[-8][1]], winrates[-8][1])\n",
    "# print(idToHero[winrates[-4][1]], winrates[-4][1])\n",
    "# print(idToHero[winrates[-9][1]], winrates[-9][1])\n",
    "\n",
    "\n",
    "# sups = [110,83,5,20,31]\n",
    "\n",
    "\n",
    "# time1 = [1, 60, 83, 85, 43]\n",
    "# time2 = [17, 42, 108, 68, 31]\n",
    "# # heroes = [71,42,6,81,4]\n",
    "winrate = [wr_pairs[hero, hero] for hero in bom2]\n",
    "avg = np.mean(winrate)\n",
    "print(avg)\n",
    "\n",
    "# sups = [110, 37, 83, 20, 5]\n",
    "# cores = [71,42,6,81,4]\n",
    "\n",
    "# time bom: Morphling, Lycanthrope, Centaur, Elder Titan e Skywrath Mage\n",
    "\n",
    "# time pain: Morphling, Ember Spirit, Warlock, Omniknight e Tusk\n",
    "# pain = [10, 106, 37, 57, 100]\n",
    "\n",
    "print([idToHero[id] for id in bom1])\n",
    "print([idToHero[id] for id in bom2])\n",
    "# print([idToHero[id] for id in time2])\n",
    "\n",
    "#time 1: Anti-Mage, Night Stalker, Treant, Undying e Death Prophet\n",
    "#time 2: Storm Spirit, Wraith King, Underlord, Ancient Apparation e Lich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_input(rad, dire):\n",
    "    input = np.zeros((121 + 75))\n",
    "    for hero in  rad:\n",
    "        input[hero] = 1\n",
    "    for hero in dire:\n",
    "        input[hero] = -1\n",
    "    \n",
    "    counter = 121\n",
    "    \n",
    "    for hero1 in rad:\n",
    "            for hero2 in rad:\n",
    "                input[counter] = wr_pairs[hero1, hero2]\n",
    "                counter += 1\n",
    "              \n",
    "  \n",
    "    for hero1 in dire:\n",
    "            for hero2 in dire:\n",
    "                input[counter] = -wr_pairs[hero1, hero2]\n",
    "                counter += 1\n",
    "   \n",
    "    for hero1 in rad:\n",
    "            for hero2 in dire:\n",
    "                input[counter] = wr_counters[hero1, hero2]\n",
    "                counter += 1\n",
    "                \n",
    "    return [input]\n",
    "\n",
    "bom1 = [106, 77, 96, 7, 101]\n",
    "bom2 = [93, 27, 14, 49, 99]\n",
    "\n",
    "\n",
    "print([idToHero[id] for id in bom1])\n",
    "print([idToHero[id] for id in bom2])\n",
    "\n",
    "clf.predict_proba(gen_input(bom1, bom2))\n",
    "\n",
    "#0.74432872\n",
    "#0.79667151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bom1 = []\n",
    "bom2_correct = [93, 27, 14, 49, 99]\n",
    "bom2 = []\n",
    "\n",
    "def add_new_hero(bom1, bom2):\n",
    "    i = len(bom1)\n",
    "    bom2.append(bom2_correct[i])\n",
    "    \n",
    "    \n",
    "    bom1.append(-1)\n",
    "    \n",
    "    best_hero = -1\n",
    "    best_chance = 0\n",
    "    \n",
    "    for hero in range(121):\n",
    "        hero_name = idToHero.get(hero, \"undefined\")\n",
    "        if hero in bom1 or hero in bom2 or hero_name == \"undefined\": continue\n",
    "            \n",
    "        bom1[i] = hero\n",
    "        input = gen_input(bom1, bom2)\n",
    "        win_chance = clf.predict_proba(input)[0][1]\n",
    "            \n",
    "        if win_chance > best_chance:\n",
    "            best_hero = hero\n",
    "            best_chance = win_chance\n",
    "    \n",
    "    bom1[i] = best_hero\n",
    "    \n",
    "add_new_hero(bom1, bom2)\n",
    "add_new_hero(bom1, bom2)\n",
    "add_new_hero(bom1, bom2)\n",
    "add_new_hero(bom1, bom2)\n",
    "add_new_hero(bom1, bom2)\n",
    "print([idToHero.get(hero, \"undefined\") for hero in bom1])\n",
    "            \n",
    "\n",
    "# input = gen_input(bom1, bom2)\n",
    "# win_chance = clf.predict_proba(input)[0][1]\n",
    "# print('CHANCE: ', win_chance)\n",
    "\n",
    "# # best = []\n",
    "\n",
    "\n",
    "# for hero in range(121):\n",
    "#     if hero in bom1 or hero in bom2: continue\n",
    "#     bom1[3] = hero\n",
    "#     input = gen_input(bom1, bom2)\n",
    "#     win_chance = clf.predict_proba(input)[0][1]\n",
    "#     hero_name = idToHero.get(hero, \"undefined\")\n",
    "#     if hero_name != \"undefined\":\n",
    "#         best.append((win_chance, hero_name))\n",
    "    \n",
    "# best.sort()\n",
    "# print(best[-10:])\n",
    "# print([idToHero[id] for id in bom1])\n",
    "# print([idToHero[id] for id in bom2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_heroes(match):\n",
    "    rad = [id for (id, team) in enumerate(match) if team == 1]\n",
    "    dire = [id for (id, team) in enumerate(match) if team == -1]\n",
    "    print('Rad:', [idToHero[id] for id in rad])\n",
    "    print('Dire:', [idToHero[id] for id in dire])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.loadtxt('dota_recent_new.txt', dtype=np.int64)\n",
    "# m = m[ : 50000]\n",
    "# print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_synnergy(lines):\n",
    "    matches_pairs = np.zeros((121, 121))\n",
    "    wins_pairs = np.zeros((121, 121)) \n",
    "    wr_pairs = np.zeros((121, 121))\n",
    "\n",
    "    for line in lines:\n",
    "        rad_wins = line[1] == 1\n",
    "        dire_wins = not rad_wins\n",
    "        heroes = line[3:]\n",
    "        rad = heroes[:5]\n",
    "        dire = heroes[5:]\n",
    "\n",
    "        for team in [rad, dire]:\n",
    "            for hero1 in team:\n",
    "                for hero2 in team:\n",
    "                    matches_pairs[hero1, hero2] += 1\n",
    "\n",
    "                    if rad_wins and hero1 in rad:\n",
    "                        wins_pairs[hero1, hero2] += 1 \n",
    "                    elif dire_wins and hero2 in dire:\n",
    "                        wins_pairs[hero1, hero2] += 1\n",
    "\n",
    "    matches_pairs[matches_pairs == 0] = 1\n",
    "    wr_pairs = wins_pairs / matches_pairs\n",
    "    return wr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syn():\n",
    "    syn_table = np.zeros((121, 121))\n",
    "    \n",
    "    for hero1 in range(121):\n",
    "        for hero2 in range(121):\n",
    "            syn_table[hero1, hero2] = wr_pairs[hero1, hero2] - (wr_pairs[hero1, hero1] + wr_pairs[hero2, hero2]) / 2\n",
    "            \n",
    "    return syn_table\n",
    "\n",
    "syn_table = syn()\n",
    "print(syn_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes = [(syn_table[hero1, hero2], (idToHero.get(hero1, \"undefined\"), idToHero.get(hero2, \"undefined\"))) for hero1 in range(121) for hero2 in range(121) if hero1 < hero2]\n",
    "heroes.sort()\n",
    "print(heroes[-10:])\n",
    "\n",
    "\n",
    "# def choose_best(table):\n",
    "#     best_heroes = [(-1,-1)\n",
    "#     val = 0\n",
    "    \n",
    "#     for hero1 in range(121):\n",
    "#         for hero2 in range(121):\n",
    "#             if table[hero1, hero2] > val:\n",
    "#                 val = table[hero1, hero2]\n",
    "#                 best_heroes = (hero1, hero2)\n",
    "            \n",
    "#     return best_heroes\n",
    "\n",
    "# hero1, hero2 = choose_best(syn_table)\n",
    "# print(idToHero[hero1],idToHero[hero2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_counters(lines):\n",
    "    matches_counter = np.zeros((121, 121))\n",
    "    wins_counter = np.zeros((121, 121)) \n",
    "    wr_counter = np.zeros((121, 121))\n",
    "\n",
    "    for line in lines:\n",
    "        rad_wins = line[1] == 1\n",
    "        dire_wins = not rad_wins\n",
    "        heroes = line[3:]\n",
    "        rad = heroes[:5]\n",
    "        dire = heroes[5:]\n",
    "\n",
    "        for hero1 in rad:\n",
    "            for hero2 in dire:\n",
    "                matches_counter[hero1, hero2] += 1\n",
    "                matches_counter[hero2, hero1] += 1\n",
    "                if rad_wins: wins_counter[hero1, hero2] += 1\n",
    "                else: wins_counter[hero2, hero1] += 1\n",
    "\n",
    "    wins_counter[matches_counter == 0] = 1\n",
    "    matches_counter[matches_counter == 0] = 1\n",
    "    wr_counter = wins_counter / matches_counter\n",
    "    return wr_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.shuffle(m)\n",
    "factor = 0.9\n",
    "train_size = int(len(m) * factor)\n",
    "wr_pairs = compute_synnergy(m[: train_size])\n",
    "wr_counters = compute_counters(m[ : train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.8328485 2.4001634 3.0719135 6.0134606 2.9437985 3.4359043 2.9478126\n",
      " 1.5594354 4.5078073 3.8357077 2.3446088 0.        2.2712998 4.891877\n",
      " 3.109836  5.120476  4.1776924 1.5204406 4.612071  2.028448 ]\n"
     ]
    }
   ],
   "source": [
    "# res = encoder.predict(inputs)\n",
    "print(res[1])\n",
    "cod_inputs = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_51 (InputLayer)        (None, 121)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 20)                2440      \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 121)               2541      \n",
      "=================================================================\n",
      "Total params: 4,981\n",
      "Trainable params: 4,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(200000, 121)\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "180000/180000 [==============================] - 3s 19us/step - loss: -39.9775 - categorical_accuracy: 0.1792 - val_loss: -54.5383 - val_categorical_accuracy: 0.2107\n",
      "Epoch 2/10\n",
      "180000/180000 [==============================] - 3s 15us/step - loss: -55.0342 - categorical_accuracy: 0.2090 - val_loss: -55.1239 - val_categorical_accuracy: 0.2134\n",
      "Epoch 3/10\n",
      "180000/180000 [==============================] - 3s 15us/step - loss: -55.3776 - categorical_accuracy: 0.2090 - val_loss: -55.3275 - val_categorical_accuracy: 0.2108\n",
      "Epoch 4/10\n",
      "180000/180000 [==============================] - 3s 16us/step - loss: -55.5470 - categorical_accuracy: 0.2106 - val_loss: -55.4492 - val_categorical_accuracy: 0.2159\n",
      "Epoch 5/10\n",
      "180000/180000 [==============================] - 3s 16us/step - loss: -55.6715 - categorical_accuracy: 0.2134 - val_loss: -55.5572 - val_categorical_accuracy: 0.2118\n",
      "Epoch 6/10\n",
      "180000/180000 [==============================] - 3s 16us/step - loss: -55.7764 - categorical_accuracy: 0.2147 - val_loss: -55.6405 - val_categorical_accuracy: 0.2167\n",
      "Epoch 7/10\n",
      "180000/180000 [==============================] - 3s 16us/step - loss: -55.8709 - categorical_accuracy: 0.2164 - val_loss: -55.7281 - val_categorical_accuracy: 0.2185\n",
      "Epoch 8/10\n",
      "180000/180000 [==============================] - 3s 17us/step - loss: -55.9580 - categorical_accuracy: 0.2178 - val_loss: -55.8073 - val_categorical_accuracy: 0.2261\n",
      "Epoch 9/10\n",
      "180000/180000 [==============================] - 3s 17us/step - loss: -56.0420 - categorical_accuracy: 0.2196 - val_loss: -55.8818 - val_categorical_accuracy: 0.2251\n",
      "Epoch 10/10\n",
      "180000/180000 [==============================] - 3s 15us/step - loss: -56.1215 - categorical_accuracy: 0.2210 - val_loss: -55.9584 - val_categorical_accuracy: 0.2214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcb4652fcc0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "\n",
    "encoding_dim = 20\n",
    "\n",
    "input = Input(shape=(121,))\n",
    "encoded = Dense(encoding_dim, activation='relu', activity_regularizer=regularizers.l1(10e-5))(input)\n",
    "decoded = Dense(121, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input, decoded)\n",
    "print(autoencoder.summary())\n",
    "\n",
    "encoder = Model(input, encoded)\n",
    "#print(encoder.summary())\n",
    "\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "#print(decoder.summary())\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "train_size = int(len(inputs) * 0.9)\n",
    "print(inputs.shape)\n",
    "autoencoder.fit(inputs[: train_size], inputs[: train_size], validation_data=(inputs[train_size:], inputs[train_size:]), epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_51 (InputLayer)        (None, 121)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 20)                2440      \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 10000)             210000    \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 1000)              10001000  \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 10,313,641\n",
      "Trainable params: 10,313,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "180000/180000 [==============================] - 933s 5ms/step - loss: 0.6661 - acc: 0.6037 - val_loss: 0.6685 - val_acc: 0.5965\n",
      "Epoch 2/10\n",
      "180000/180000 [==============================] - 894s 5ms/step - loss: 0.6636 - acc: 0.6071 - val_loss: 0.6691 - val_acc: 0.5961\n",
      "Epoch 3/10\n",
      "180000/180000 [==============================] - 899s 5ms/step - loss: 0.6625 - acc: 0.6084 - val_loss: 0.6692 - val_acc: 0.5958\n",
      "Epoch 4/10\n",
      "180000/180000 [==============================] - 901s 5ms/step - loss: 0.6616 - acc: 0.6094 - val_loss: 0.6722 - val_acc: 0.5926\n",
      "Epoch 5/10\n",
      "180000/180000 [==============================] - 915s 5ms/step - loss: 0.6609 - acc: 0.6109 - val_loss: 0.6711 - val_acc: 0.5958\n",
      "Epoch 6/10\n",
      "180000/180000 [==============================] - 1164s 6ms/step - loss: 0.6602 - acc: 0.6122 - val_loss: 0.6713 - val_acc: 0.5936\n",
      "Epoch 7/10\n",
      "180000/180000 [==============================] - 1171s 7ms/step - loss: 0.6597 - acc: 0.6123 - val_loss: 0.6717 - val_acc: 0.5939\n",
      "Epoch 8/10\n",
      "180000/180000 [==============================] - 856s 5ms/step - loss: 0.6592 - acc: 0.6123 - val_loss: 0.6696 - val_acc: 0.5936\n",
      "Epoch 9/10\n",
      "180000/180000 [==============================] - 794s 4ms/step - loss: 0.6587 - acc: 0.6125 - val_loss: 0.6708 - val_acc: 0.5923\n",
      "Epoch 10/10\n",
      "180000/180000 [==============================] - 796s 4ms/step - loss: 0.6583 - acc: 0.6129 - val_loss: 0.6708 - val_acc: 0.5933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcbbc3f7668>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adagrad, Adam\n",
    "\n",
    "layer1 = Dense(10000, activation='relu')(encoded)\n",
    "layer2 = Dense(1000, activation='relu')(layer1)\n",
    "layer3 = Dense(100, activation='relu')(layer2)\n",
    "# mid = Dropout(0.4)(layer1)\n",
    "layer4 = Dense(1, activation='sigmoid')(layer3)\n",
    "\n",
    "model = Model(input, layer4)\n",
    "\n",
    "# sgd = SGD(lr=0.05)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy'], \n",
    "              optimizer='adadelta')\n",
    "\n",
    "model.fit(inputs[: train_size], outputs[: train_size], validation_data=(inputs[train_size:], outputs[train_size:]), epochs=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wr_counters[50, 63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(lines):\n",
    "#     inputs = np.zeros((len(lines), 121))\n",
    "    inputs = np.zeros((len(lines), 121))\n",
    "    outputs = np.zeros((len(lines)))\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        counter = 0\n",
    "        \n",
    "        line = lines[i]\n",
    "        input = inputs[i]\n",
    "        outputs[i] = line[1]\n",
    "        game_type = line[2]\n",
    "        \n",
    "        heroes = line[3:]\n",
    "        rad = heroes[:5]\n",
    "        dire = heroes[5:]\n",
    "        \n",
    "        for hero in rad:\n",
    "            input[hero] = 1\n",
    "\n",
    " \n",
    "        for hero in dire:\n",
    "            input[hero] = -1\n",
    "            \n",
    "#         counter = 121    \n",
    "        \n",
    "#         for hero1 in rad:\n",
    "#             for hero2 in rad:\n",
    "#                 input[counter] = wr_pairs[hero1, hero2]\n",
    "#                 counter += 1\n",
    "              \n",
    "  \n",
    "#         for hero1 in dire:\n",
    "#                 for hero2 in dire:\n",
    "#                     input[counter] = -wr_pairs[hero1, hero2]\n",
    "#                     counter += 1\n",
    "\n",
    "#         for hero1 in rad:\n",
    "#                 for hero2 in dire:\n",
    "#                     input[counter] = wr_counters[hero1, hero2]\n",
    "#                     counter += 1\n",
    "\n",
    "\n",
    "    return (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. -1.  0.  0. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  1. -1.  0.  0.  0. -1.  0.  0.  0.  0.  0. -1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs, outputs = format_data(m)\n",
    "#print(len(inputs))\n",
    "print(inputs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = inputs[10]\n",
    "#match[35] = 0\n",
    "print(len([v for v in match if v <= -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adagrad, Adam\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# limit = 20000\n",
    "limit = len(inputs)\n",
    "train_size = int(limit * 0.9)\n",
    "test_size = limit - train_size\n",
    "train_in = inputs[ : train_size]\n",
    "train_out = outputs[: train_size]\n",
    "test_in = inputs[train_size : limit]\n",
    "test_out = outputs[train_size : limit]\n",
    "\n",
    "model.add(Dense(10000, activation='relu', input_dim=len(inputs[0])))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.05)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              #optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "#               optimizer='adadelta',\n",
    "              optimizer=sgd,\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "\n",
    "model.fit(train_in, train_out,\n",
    "          epochs=20,\n",
    "          validation_data=(test_in, test_out))\n",
    "\n",
    "\n",
    "result = model.evaluate(test_in, test_out)\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200, max_features=11, min_samples_split=2, max_depth=None, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(5, weights='distance', n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "# from sklearn import svm\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(data['train']['in'], data['train']['out'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=2000, learning_rate=1.0, max_depth=1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = BaggingClassifier(LogisticRegression(),\n",
    "                             max_samples=0.5, max_features=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf = VotingClassifier(estimators=[('for', clf_forest), ('naive', clf_naive), ('log', clf_log)], voting='soft', weights=[1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline:\n",
    "    def fit(inputs, outputs):\n",
    "        pass\n",
    "    \n",
    "    def _pred(self, input):\n",
    "        rad = []\n",
    "        dire = []\n",
    "        \n",
    "        for hero_id, val in enumerate(input):\n",
    "            if val == 1: rad.append(hero_id)\n",
    "            elif val == -1: dire.append(hero_id)\n",
    "          \n",
    "#         sinergy_rad = np.average([wr_pairs[hero, hero] for hero in rad])\n",
    "#         sinergy_dire = np.average([wr_pairs[hero, hero] for hero in dire])\n",
    "        \n",
    "        sinergy_rad = np.average([wr_pairs[hero1, hero2] for hero2 in rad for hero1 in rad])\n",
    "        sinergy_dire = np.average([wr_pairs[hero1, hero2] for hero2 in dire for hero1 in dire])\n",
    "        \n",
    "        #print(sinergy_dire)\n",
    "        \n",
    "        return 1 if sinergy_rad > sinergy_dire else 0\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        return [self._pred(input) for input in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Baseline()\n",
    "\n",
    "pred = x.predict(inputs[train_size:])\n",
    "correct = outputs[train_size:]\n",
    "\n",
    "right = 0\n",
    "\n",
    "for p,c in zip(pred,correct):\n",
    "    if p == c:\n",
    "        right += 1\n",
    "\n",
    "print(right / len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [74.4, 69.5, 63.5, 69.0, 74.5, 52.3, 71.7, 68.6, 59.2]\n",
    "print([0.93 * val for val in vals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "clf = LogisticRegressionCV(cv=5, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_size = int(len(inputs) * 0.9)\n",
    "test_size = len(inputs) - train_size\n",
    "\n",
    "clf = clf.fit(cod_inputs[:train_size], outputs[:train_size])\n",
    "preds = clf.predict(cod_inputs[train_size:])\n",
    "correct = outputs[train_size:]\n",
    "\n",
    "\n",
    "print(accuracy_score(correct, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "heroes = pd.read_csv('dota-2-match-prediction-master/data/MatchOverviewTraining.csv').values\n",
    "df_extra = pd.read_csv('dota-2-match-prediction-master/data/MatchDetail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(heroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(heroes, df_extra):\n",
    "    matches = np.zeros((10000, 121), dtype=int)\n",
    "    out = np.zeros((10000), dtype=int)\n",
    "    \n",
    "    for (i, line) in enumerate(heroes):\n",
    "        out[i] = 1 if line[-1] else 0\n",
    "        match_id = line[0]\n",
    "        heroes = line[1:]\n",
    "        rad = heroes[:5]\n",
    "        dire = heroes[5:-1]\n",
    "        \n",
    "        for hero in rad:\n",
    "            matches[i][hero] = 1\n",
    "            \n",
    "        for hero in dire:\n",
    "            matches[i][hero] = -1\n",
    "            \n",
    "        \n",
    "#         counter = 121\n",
    "        \n",
    "#         exp_gold = df_extra.loc[df_extra['match_id'] == match_id].values\n",
    "#         for (j, data) in enumerate(exp_gold):\n",
    "#             matches[i][counter + 2*j] = data[4]\n",
    "#             matches[i][counter + 2*j + 1] = data[14]\n",
    "            \n",
    "    return matches, out\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, output = gen_data(heroes, df_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adagrad, Adam\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "train_size = int(len(input) * 0.9)\n",
    "test_size = len(input) - train_size\n",
    "train_in = input[ : train_size]\n",
    "train_out = output[: train_size]\n",
    "test_in = input[train_size : ]\n",
    "test_out = output[train_size : ]\n",
    "\n",
    "model.add(Dense(100, activation='relu', input_dim=len(input[0])))\n",
    "#model.add(Dropout(0.1))\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#sgd = SGD(lr=0.05)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              #optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              optimizer='adadelta',\n",
    "              #optimizer=sgd,\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(train_in, train_out,\n",
    "          epochs=200,\n",
    "          validation_data=(test_in, test_out))\n",
    "\n",
    "result = model.evaluate(test_in, test_out)\n",
    "\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(input[0])\n",
    "clf.predict_proba([input[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "factor = 0.9\n",
    "train_size = int(len(inputs) * factor)\n",
    "test_size = len(inputs) - train_size\n",
    "train_in, train_out, test_in, test_out = inputs[:train_size], outputs[:train_size], inputs[train_size:], outputs[train_size:]\n",
    "\n",
    "\n",
    "clf = clf.fit(train_in, train_out)\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "preds = clf.predict(test_in)\n",
    "correct = test_out\n",
    "\n",
    "print(accuracy_score(correct, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = inputs[0]\n",
    "print_heroes(match)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match[114] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match[22] = 0\n",
    "print_heroes(match)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 0\n",
    "best_chance = 0\n",
    "\n",
    "for i in range(120):\n",
    "    if match[i] != 0: continue\n",
    "    match[i] = 1\n",
    "    chance_win = clf.predict_proba([match])[0][1]\n",
    "    \n",
    "    if chance_win > best_chance:\n",
    "        best_chance = chance_win\n",
    "        best = i\n",
    "        \n",
    "    print('chance: %f hero: %s' % (chance_win, idToHero.get(i, \"N/A\")))\n",
    "    match[i] = 0\n",
    "\n",
    "print('BEST:', idToHero[best])\n",
    "match[0] = 0\n",
    "print_heroes(match)\n",
    "\n",
    "# print(len([v for v in match if v != 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "# tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                      'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "tuned_parameters = [{'n_estimators': [10, 50, 100], 'max_features': [11, 40, 121]}]\n",
    "\n",
    "scores = ['precision']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % 'precision')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
